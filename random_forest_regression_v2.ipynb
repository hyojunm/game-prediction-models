{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9eff0a3-b7da-4d9b-9585-d2149b9b2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PoissonRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from analysis import get_feature_importances, visualize_decision_trees, get_vif, wl_accuracy, season_record, runs_per_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccdf1778-1cda-4594-9970-754e1adc68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 6\n",
    "df = pd.read_csv(f'./data/baseball/training/game_data_v{version}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c146deef-52e4-4a83-83d4-4c44637b17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the appropriate training and testing data based on home/away, dropping columns as needed\n",
    "def create_data(drop_cols=['away_score', 'home_score', 'away_team', 'home_team'], y_col='away_score', split_by='random'):\n",
    "    y = df[y_col]\n",
    "    x = df.drop(drop_cols, axis=1)\n",
    "\n",
    "    if split_by == 'season':\n",
    "        x_train, x_test = x.iloc[0:13047], x.iloc[13047:]\n",
    "        y_train, y_test = y.iloc[0:13047], y.iloc[13047:]\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfc7d532-0ce0-494b-9063-7564f1340435",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_away, x_test_away, y_train_away, y_test_away = create_data(y_col='away_score', split_by='season')\n",
    "x_train_home, x_test_home, y_train_home, y_test_home = create_data(y_col='home_score', split_by='season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9242c6c7-91b9-4058-9f5e-58c067022b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_away = RandomForestRegressor(n_estimators=3, max_features='sqrt')\n",
    "model_home = RandomForestRegressor(n_estimators=3, max_features='sqrt')\n",
    "\n",
    "model_away.fit(x_train_away, y_train_away)\n",
    "model_home.fit(x_train_home, y_train_home)\n",
    "\n",
    "pred_away = model_away.predict(x_test_away)\n",
    "pred_home = model_home.predict(x_test_home)\n",
    "\n",
    "results = pd.DataFrame({'away_pred': pred_away, 'home_pred': pred_home, 'away_true': y_test_away, 'home_true': y_test_home})\n",
    "results.describe()\n",
    "\n",
    "print('RANDOM FOREST REGRESSION MODEL (v2 - with increased variance)')\n",
    "print(f'Accuracy: {wl_accuracy(results)}%')\n",
    "print('-' * 30)\n",
    "season_record(df, results)\n",
    "print('-' * 30)\n",
    "runs_per_game(df, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2847edbc-6b1f-4ee0-9f0e-2d91dcf2cbc7",
   "metadata": {},
   "source": [
    "By using fewer decision trees, the aggregate records came out to be more realistic - even if it did come at the cost of losing some accuracy. Looking at the histogram below, we can see that this modified version has a mean accuracy of about 53%, which is still better than a random guessing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731dd63-fda1-47d4-99c2-221951479e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "\n",
    "for i in range(100):\n",
    "    model_away.fit(x_train_away, y_train_away)\n",
    "    model_home.fit(x_train_home, y_train_home)\n",
    "    \n",
    "    pred_away = model_away.predict(x_test_away)\n",
    "    pred_home = model_home.predict(x_test_home)\n",
    "    \n",
    "    results = pd.DataFrame({'away_pred': pred_away, 'home_pred': pred_home, 'away_true': y_test_away, 'home_true': y_test_home})\n",
    "    results.describe()\n",
    "    \n",
    "    acc.append(wl_accuracy(results))\n",
    "\n",
    "\n",
    "print(pd.DataFrame(acc).describe())\n",
    "\n",
    "plt.hist(acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5116d8-9b3a-4351-a7d6-4a450f4e051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_decision_trees(model_home, x_test_home.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
